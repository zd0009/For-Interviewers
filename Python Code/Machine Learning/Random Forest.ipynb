{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSCA 31009 Machine Learning & Predictive Analytics\n",
    "## Assignment 3\n",
    "## Duo Zhou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Binary Classification: \n",
    "\n",
    "For assignment #4 we will be working with a credit default data set. The data includes various features around financial history and demographic information. The target variable is \"default payment next week\", which is just a binary flag of whether a customer defaults on a payment in the next week.\n",
    "\n",
    "You will need to use the Random Forest Classifier from sklearn in order to build a classifier to predict if a customer is likely to default. You will also need to use the GridSearch CV for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Processing:\n",
    "\n",
    "a) Import the data: shape should be (30000,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('data/default of credit card clients.xls',index_col=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Remove any rows that have missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(how='any', axis = 0, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) The target / y variable is \"default payment next month\" column. Keep all predictors for the X df except for the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 23) (30000,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns='default payment next month')\n",
    "y = df['default payment next month']\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Split data into train / test set using an 70/30 split. Recall that you should be generating an X_train, X_test, y_train, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 23) (9000, 23) (21000,) (9000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Random Forest Classifier - Base Model:\n",
    "\n",
    "Start by creating a simple Random Forest only using default parameters.\n",
    "\n",
    "a) Use the RandomForestClassifier in sklearn. Fit your model on the training data & make sure to add a random_state (check documentation to confirm how to do this). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zd000\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Use the fitted model to predict on test data. Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Calculate the confusion matrix and classification report (both are in sklearn.metrics). \n",
    "\n",
    "d) Calculate the roc_auc_score for this model. There are many ways to do this, but an example is to use the probabilities from step B and utilize the roc_auc_score from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.8045555555555556\n",
      "\n",
      "Test Confusion Matrix\n",
      "[[6600  437]\n",
      " [1322  641]]\n",
      "\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      7037\n",
      "           1       0.59      0.33      0.42      1963\n",
      "\n",
      "    accuracy                           0.80      9000\n",
      "   macro avg       0.71      0.63      0.65      9000\n",
      "weighted avg       0.78      0.80      0.78      9000\n",
      "\n",
      "\n",
      "Test ROC AUC\n",
      "0.7253645330471041\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", clf.score(X_test, y_test))\n",
    "print(\"\\nTest Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_test, y_test_pred))\n",
    "print(\"\\nTest Classification Report\")\n",
    "print(skm.classification_report(y_test, y_test_pred))\n",
    "print(\"\\nTest ROC AUC\")\n",
    "# limit to probability for class = 1 \n",
    "print(skm.roc_auc_score(y_test, y_test_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Calculate predictions for the training data & build the classification report & roc_auc_score. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "y_train_proba = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9799523809523809\n",
      "\n",
      "Train Confusion Matrix\n",
      "[[16294    33]\n",
      " [  388  4285]]\n",
      "\n",
      "Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     16327\n",
      "           1       0.99      0.92      0.95      4673\n",
      "\n",
      "    accuracy                           0.98     21000\n",
      "   macro avg       0.98      0.96      0.97     21000\n",
      "weighted avg       0.98      0.98      0.98     21000\n",
      "\n",
      "\n",
      "Train ROC AUC\n",
      "0.9990750441133462\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Score:\", clf.score(X_train, y_train))\n",
    "print(\"\\nTrain Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_train, y_train_pred))\n",
    "print(\"\\nTrain Classification Report\")\n",
    "print(skm.classification_report(y_train, y_train_pred))\n",
    "print(\"\\nTrain ROC AUC\")\n",
    "# limit to probability for class = 1 \n",
    "print(skm.roc_auc_score(y_train, y_train_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result above, we can see that for default prediction(y=1) training f1_score is 0.95 and test f1-score is 0.42. The overall accuracy is 0.98 for training set and 0.8 for test set. The training ROC AUC score is 0.9991 and test ROC AUC score is 0.7254. All three scores are very close to 1 in the training set, but drop drastically in the test set. This is a clear sign of overfitting since the model performance droped a lot when applied to new unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Random Forest Classifier - Grid Search:<br>\n",
    "<br>\n",
    "Start by creating a simple Random Forest only using default parameters.<br>\n",
    "<br>\n",
    "a) Use the RandomForestClassifier along with the GridSearchCV tool. Run the GridSearchCV using the following: <br>\n",
    "<br>\n",
    "n_estimators: 50, 100, 500<br>\n",
    "max_features: 2, 4, sqrt<br>\n",
    "max_depth: 6, 8, 10, 12<br>\n",
    "Note: Feel free to try out more parameters, the above is the bare minimum for this assignment. The goal of the above parameters are to try a large but fairly fast grid search. This took about 8 minutes to run on your TAs computer but that time will vary greatly based on computational resources. <br>\n",
    "<br>\n",
    "Use 5 cross-fold and for scoring use \"roc_auc\" (this is the score that will be referenced when identifying the best parameters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   50.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 13.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [6, 8, 10, 12],\n",
       "                         'max_features': [2, 4, 'sqrt'],\n",
       "                         'n_estimators': [50, 100, 500, 2000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [50, 100, 500,2000],\n",
    "    'max_features': [2, 4, 'sqrt'],\n",
    "    'max_depth': [6, 8, 10, 12]\n",
    "}\n",
    "\n",
    "clf1 = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(clf1, parameters, cv=5, scoring='roc_auc',refit=True, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Identify the best performing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 12, 'max_features': 2, 'n_estimators': 500}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=12, max_features=2, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "c) Use the best estimator model to predict on test data. Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes.\n",
    "\n",
    "d) Calculate the confusion matrix and classification report (both are in sklearn.metrics). \n",
    "\n",
    "e) Calculate the roc_auc_score for this model.\n",
    "\n",
    "f) Calculate predictions for the training data & build the confusion matrix, classification report & roc_auc_score. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = grid_search.best_estimator_\n",
    "\n",
    "y_train_pred1 = bm.predict(X_train)\n",
    "y_test_pred1 = bm.predict(X_test)\n",
    "\n",
    "y_train_proba1 = bm.predict_proba(X_train)\n",
    "y_test_proba1 = bm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8774285714285714\n",
      "\n",
      "Train Confusion Matrix\n",
      "[[16167   160]\n",
      " [ 2414  2259]]\n",
      "\n",
      "Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     16327\n",
      "           1       0.93      0.48      0.64      4673\n",
      "\n",
      "    accuracy                           0.88     21000\n",
      "   macro avg       0.90      0.74      0.78     21000\n",
      "weighted avg       0.88      0.88      0.86     21000\n",
      "\n",
      "\n",
      "Train ROC AUC: 0.91\n",
      "-----------------------------------------------------------\n",
      "Test Score: 0.8174444444444444\n",
      "\n",
      "Test Confusion Matrix\n",
      "[[6713  324]\n",
      " [1319  644]]\n",
      "\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7037\n",
      "           1       0.67      0.33      0.44      1963\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.75      0.64      0.67      9000\n",
      "weighted avg       0.80      0.82      0.79      9000\n",
      "\n",
      "\n",
      "Test ROC AUC: 0.78\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Score:\", bm.score(X_train, y_train))\n",
    "print(\"\\nTrain Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_train, y_train_pred1))\n",
    "print(\"\\nTrain Classification Report\")\n",
    "print(skm.classification_report(y_train, y_train_pred1))\n",
    "print(\"\\nTrain ROC AUC:\", round(skm.roc_auc_score(y_train, y_train_proba1[:,1]), 2))\n",
    "print(\"-----------------------------------------------------------\")\n",
    "\n",
    "print(\"Test Score:\", bm.score(X_test, y_test))\n",
    "print(\"\\nTest Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_test, y_test_pred1))\n",
    "print(\"\\nTest Classification Report\")\n",
    "print(skm.classification_report(y_test, y_test_pred1))\n",
    "print(\"\\nTest ROC AUC:\", round(skm.roc_auc_score(y_test, y_test_proba1[:,1]), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Are there signs of overfitting? Why or why not?\n",
    "Comapre to base model in Question 2, all three scores we discussed in Question 2, default prediction(y=1) f1_score, over all accuracy and  ROC AUC score, are lower when applying our best Q3 model to training data set. However, all three scores increased when applying Q3 best model to the test data set. The difference between train and test scores are much smaller when applying Q3 best model. This clearly indicates that Q3 best model overfit less than Q2 base model. If we deploy Q3 best model, it will perform much better than Q2 base model when applied to new unseen data. Since all three scores are reasonably close between train and test in Q3 model, we can say that overfitting is not that significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create a feature importance plot for your best performing model.\n",
    "\n",
    "a) What are the top 5 features for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x263936c1448>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi = pd.DataFrame({'name': X.columns, 'importance': bm.feature_importances_})\n",
    "fi.sort_values('importance', ascending=False, inplace=True)\n",
    "fi.plot.bar(x='name', y='importance',title='Feature Importance Ranking of Q3 Best Model',figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graph above, top 5 features for this model are PAY_0, PAY_2, PAY_3, PAY_4, PAY_5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Conceptual Questions:\n",
    "\n",
    "##### a) What are the best parameters from the Grid Search in Question # 3? Does the Model from #3 outperform Model #2? Explain why <br>\n",
    "<br>\n",
    "The best parameters from the Grid Search in Question #3 are 'max_depth': 12, 'max_features': 2, 'n_estimators': 500.<br>\n",
    "\n",
    "Model #3 performed better when applied to test data and Model #2 performed better when applied to training data. Since Model #3 performs better when applied to new unseen data, we can say that Model #3 outperformed Model #2. Please see my discussion on overfitting in Q2 and Q3. <br>\n",
    "<br>\n",
    "\n",
    "##### b) Overfitting is always a concern in ML problems. Does Model #3 overfit data more or less than Model #2? Explain why you think this is the case.  <br>\n",
    "\n",
    "Comapre to base model in Question 2, all three scores we discussed in Question 2, default prediction(y=1) f1_score, over all accuracy and ROC AUC score, are lower when applying our best Q3 model to training data set. However, all three scores increased when applying Q3 best model to the test data set. The difference between train and test scores are much smaller when applying Q3 best model. This clearly indicates that Q3 best model overfit less than Q2 base model. <br>\n",
    "<br>\n",
    "\n",
    "##### c) The lecture notes describe the Gini Index which is the default criterion used for splitting in sklearn's version of RandomForestClassifier. How does the Gini Index work? (i.e. How is it used to build a top-performing model?). \n",
    "\n",
    "Gini Index, also known as Gini impurity, calculates the amount of probability of a specific feature that is classified incorrectly when selected randomly. If all the elements are linked with a single class then it can be called pure. <br>\n",
    "\n",
    "The Gini index varies between values 0 and 1, where 0 expresses the purity of classification, i.e. All the elements belong to a specified class or only one class exists there. And 1 indicates the random distribution of elements across various classes. The value of 0.5 of the Gini Index shows an equal distribution of elements over some classes.<br>\n",
    "\n",
    "While splitting a node, the features possessing the least value of the Gini Index would get chosen.<br>\n",
    "\n",
    "\n",
    "$G = \\sum_{k=1}^{k} p_{mk}(1-p_{mk})$ <br>\n",
    "\n",
    "where $p_{mk}$ is the proportion of training observations in the mth region that are from the kth class.\n",
    "\n",
    "The purer(smaller Gini Index) each terminal node gets, the better final model perfoms.\n",
    "\n",
    "##### d) Describe how Random Forest is different from bagging & why this difference can yield improved results.\n",
    "\n",
    "The bagging algorithm draws random bootstrap samples from your training set and we provide each tree with the full set of features. However, in addition to the bootstrap samples, Random Forest also draws random subsets of features for training the individual trees. Due to the random feature selection, the trees are more independent of each other compared to regular bagging, which often results in better predictive performance (due to better variance-bias trade-offs), and I’d say that it’s also faster than bagging, because each tree learns only from a subset of features.\n",
    "\n",
    "##### e) Describe the importance of the max_depth parameter in Random Forest. Do not just provide a definition, rather think through how bias-variance tradeoff might be impacted by the max_depth parameter.\n",
    "\n",
    "max_depth is the how many splits deep you want each tree to go. max_depth = 10, for example, would limit trees to at most 10 splits down any given branch. Samller max_depth has the consequence that our Random Forest can no longer fit the training data as closely, and is therefore more stable and can prevent overfitting. It also creates lower variance, giving our model higher bias. However severely constraining max_depth could increase the bias of each tree given that they may not be able to capture certain patterns in the data before hitting their max_depth limit. \n",
    "\n",
    "##### f) In this homework we used k-fold cross-validation while determining the optimal hyperparameters for our Random Forest model. 1) Describe how k-fold cross-validation works. 2) What benefit do we gain by using k-fold cross-validation when tuning our Random Forest model versus only using the train-test split approach?\n",
    "1)<br>\n",
    "Split the entire data randomly into K folds. The higher value of K leads to less biased model (but large variance might lead to over-fit), where as the lower value of K(k=1) is similar to the train-test split. Then validate the model using each of the K folds while train the model using the remaining folds. Records the scores/errors. Repeat this process until every K-fold serve as the test set. Then take the average of your recorded scores. That will be the performance metric for the model.<br>\n",
    "\n",
    "2)<br>\n",
    "\n",
    "K-Folds technique generally results in a less biased model compare to single train-test split. Because it ensures that every observation from the original dataset has the chance of appearing in training and test set. It is especially useful when we have a limited input data. In addition, when we tune our model, train-test split may encounter a situation where extreme outliers are all grouped into either train or test, which will cause high bias in our training model parameters or test performance. In summary, Cross-validation is usually the preferred method because it gives your model the opportunity to train on multiple train-test splits and model&test across all data points. This will capture more information from the entire data set and gives you a better indication of how well your model will perform on different unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
